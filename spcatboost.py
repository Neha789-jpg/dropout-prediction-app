# -*- coding: utf-8 -*-
"""spcatboost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sOjC8I0fxp1B3LBcJmRf21L8nYm-Wb81
"""

# ======================
# 1. Import Libraries
# ======================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE

#pip install catboost
from catboost import CatBoostClassifier

# ======================
# 2. Read CSV File
# ======================
df = pd.read_csv("dataset.csv", sep='\t')  # or sep=',' if comma-separated
print("Dataset Shape:", df.shape)
print(df.head())


# ======================
# 3. PIE CHART: Dropout vs NotDropout
# ======================
df["TargetBinary"] = df["Target"].copy()
df["TargetBinary"][df["TargetBinary"] != "Dropout"] = "NotDropout"

plt.figure(figsize=(5,5))
df["TargetBinary"].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=['red','green'])
plt.title("Dropout vs NotDropout Distribution")
plt.ylabel('')
plt.show()

# ======================
# 4. MISSING VALUES HEATMAP
# ======================
plt.figure(figsize=(10,5))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title("Missing Values Heatmap")
plt.show()

# ======================
# 5. DROP NOISY COLUMNS
# ======================
drop_cols = ["Nacionality", "Father's occupation", "Mother's occupation", "Application order"]
df = df.drop(columns=[c for c in drop_cols if c in df.columns])

# ======================
# 6. FEATURE ENGINEERING
# ======================
df["failed_1st"] = df["Curricular units 1st sem (evaluations)"] - df["Curricular units 1st sem (approved)"]
df["failed_2nd"] = df["Curricular units 2nd sem (evaluations)"] - df["Curricular units 2nd sem (approved)"]

df["total_enrolled"] = df["Curricular units 1st sem (enrolled)"] + df["Curricular units 2nd sem (enrolled)"]
df["total_approved"] = df["Curricular units 1st sem (approved)"] + df["Curricular units 2nd sem (approved)"]
df["total_failed"] = df["failed_1st"] + df["failed_2nd"]
df["total_passed"] = df["total_approved"]
df["avg_grade"] = (df["Curricular units 1st sem (grade)"] + df["Curricular units 2nd sem (grade)"]) / 2

df["1st_sem_pass_ratio"] = df["Curricular units 1st sem (approved)"] / (df["Curricular units 1st sem (enrolled)"] + 1)
df["2nd_sem_pass_ratio"] = df["Curricular units 2nd sem (approved)"] / (df["Curricular units 2nd sem (enrolled)"] + 1)
df["total_pass_ratio"] = df["total_passed"] / (df["total_enrolled"] + 1)
df["fail_ratio"] = df["total_failed"] / (df["total_enrolled"] + 1)

df["risk_score"] = df["fail_ratio"] * 3 + (1 - df["total_pass_ratio"]) * 2 + (5 - df["avg_grade"]) * 0.5

# ======================
#  CORRELATION HEATMAP
# ======================
plt.figure(figsize=(12,8))
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
sns.heatmap(df[numeric_cols].corr(), annot=False, fmt=".2f", cmap='coolwarm', cbar=True)
plt.title("Correlation Heatmap Between Features")
plt.show()

# ======================
# 7. TARGET & FEATURES
# ======================
y = df["TargetBinary"]
X = df.drop(["Target", "TargetBinary"], axis=1)

le = LabelEncoder()
y_encoded = le.fit_transform(y)

# ======================
# 8. TRAIN-TEST SPLIT
# ======================
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded
)

cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()

# ======================
# 9. BALANCE DATA WITH SMOTE
# ======================
sm = SMOTE(random_state=42)
X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)

# ======================
# 10. CATBOOST MODEL
# ======================
cat_feature_indices = [X.columns.get_loc(col) for col in cat_cols]

model = CatBoostClassifier(
    iterations=2000,
    learning_rate=0.015,
    depth=10,
    l2_leaf_reg=5,
    loss_function='Logloss',
    eval_metric='Accuracy',
    random_seed=42,
    verbose=200,
    early_stopping_rounds=150
)

model.fit(
    X_train_bal, y_train_bal,
    cat_features=cat_feature_indices,
    eval_set=(X_test, y_test)
)

#y_pred = model.predict(X_test).astype(int)
y_pred_proba = model.predict_proba(X_test)[:, 1]
y_pred = (y_pred_proba > 0.7).astype(int)


# ======================
# 11. MODEL ACCURACY & REPORTS
# ======================
print("✅ CatBoost Binary Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# ======================
# 12. FEATURE IMPORTANCE
# ======================
importances = model.get_feature_importance()
feature_names = X.columns

# Top 15 features
top_indices = np.argsort(importances)[::-1][:15]
plt.figure(figsize=(10,6))
sns.barplot(x=importances[top_indices], y=feature_names[top_indices], palette="viridis")
plt.title("Top 15 Features Affecting Dropout Prediction")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

import joblib

# Save as pickle
joblib.dump(model, "catboost_dropout_model.pkl")

# Optional: CatBoost native save (recommended)
model.save_model("catboost_dropout_model.cbm")

print("✅ Model saved as catboost_dropout_model.pkl and catboost_dropout_model.cbm")